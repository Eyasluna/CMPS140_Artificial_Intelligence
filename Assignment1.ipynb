{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPS 140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "95c148d1d7f3bad1a285adcc2df86994",
     "grade": false,
     "grade_id": "cell-d2d02676a6c716dd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1\n",
    "\n",
    "**DUE: Friday April 20, 2018 11:59pm**\n",
    "\n",
    "Turn in the assignment via Canvas.\n",
    "\n",
    "To write legible answers you will need to be familiar with both [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) and [Latex](https://www.latex-tutorial.com/tutorials/amsmath/)\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel→→Restart) and then run all cells (in the menubar, select Cell→→Run All).\n",
    "\n",
    "Make sure you fill in any place that says \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\", as well as your name below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAME = \"Yibo Fu\"\n",
    "STUDENT_ID = \"6666666\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b0012b5d623145240cdd19dfa65be703",
     "grade": false,
     "grade_id": "cell-fbc61605f66193a2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 1 \n",
    "\n",
    "Suppose that 13 cards are selected at random from a regular deck of 52 playing cards:\n",
    "\n",
    "a. If it is known that at least one ace has been selected, what is the probability that at least two aces have been selected?\n",
    "\n",
    "b. If it is known that the ace of hearts has been selected, what is the probability that at least two aces have been selected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a1889ce8782580117854c4f2773af870",
     "grade": true,
     "grade_id": "cell-b18eb48e93041a25",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "## [YOUR ANSWER HERE]\n",
    "\n",
    "## Answer of Question a:\n",
    "\n",
    "Event A = At leat one ace has been selected\n",
    "\n",
    "$$P(A)=1-\\frac{\\binom{13}{48}}{\\binom{13}{52}}=0.69$$\n",
    "\n",
    "Event B = At least two aces have benn selected\n",
    "\n",
    "$$P(B)=1-\\left(\\frac{\\binom{13}{48}}{\\binom{13}{52}}+\\frac{\\binom{1}{4}\\binom{12}{48}}{\\binom{13}{52}}\\right)=0.26$$\n",
    "\n",
    "so, if it is known that at least one ace has been selected, the probability that at least two aces have been selected is\n",
    "\n",
    "$$P(B\\mid A)=\\frac{P(AB)}{P(A)}=\\frac{P(B)}{P(A)}=0.37$$\n",
    "\n",
    "\n",
    "## Answer of Question b:\n",
    "\n",
    "Event A = The ace of hearts has been selected\n",
    "\n",
    "$P(A)=\\frac{\\binom{1}{1}\\binom{12}{51}}{\\binom{13}{52}}=0.15$\n",
    "\n",
    "Event B = At least two aces have been selected\n",
    "\n",
    "$P(B)=1-\\left(\\frac{\\binom{13}{48}}{\\binom{13}{52}}+\\frac{\\binom{1}{4}\\binom{12}{48}}{\\binom{13}{52}}\\right)=0.08$\n",
    "\n",
    "Event AB = At least two aces have been selected and one of them is the ace of hearts\n",
    "\n",
    "$P(AB)=\\frac{\\binom{1}{1}\\binom{1}{3}\\binom{11}{48}}{\\binom{13}{52}}+\\frac{\\binom{1}{1}\\binom{2}{3}\\binom{10}{48}}{\\binom{13}{52}}+\\frac{\\binom{1}{1}\\binom{3}{3}\\binom{9}{48}}{\\binom{13}{52}}=0.06$\n",
    "\n",
    "so, if it is known that the ace of hearts has been selected, the probability that at least two aces have been selected is\n",
    "\n",
    "$P(B\\mid A)=\\frac{P(AB)}{P(A)}=0.36$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "886ce8f1c285a0340b635a4b945e9ae9",
     "grade": false,
     "grade_id": "cell-63bc34a656b9f6e0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "\n",
    "Suppose that a person's score X on a mathematics aptitude test is a number between 0 and 1, and that a person's score on a music aptitude test is also a number between 0 and 1. Supposed further that in the population of all college students, the scores X and Y are distributed according to the following joint p.d.f.:\n",
    "\n",
    "$f(x, y) = \\frac{2}{5}(2x+3y),$ for $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$\n",
    "\n",
    "a. What proportion of college students obtain a score greater than 0.8 on the mathematics test?\n",
    "\n",
    "b. If a student's score on the music test is 0.3, what is the probability that his/her score on the mathematics test will be greater than 0.8?\n",
    "\n",
    "c. If a student's score on the mathematics test is 0.3, what is the probability that his/her score on the music test will be greater than 0.8?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e15a7a687546c8c98d80284a2bc17582",
     "grade": true,
     "grade_id": "cell-2f061f10915044a8",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "## [YOUR ANSWER HERE]\n",
    "\n",
    "$f(x, y) = \\frac{2}{5}(2x+3y),$ for $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$\n",
    "\n",
    "$f_X(x)=\\int_{-\\infty}^{+\\infty}f(x,y)dy=\\frac{2}{5}\\int_{0}^{1}(2x+3y)dy=\\frac{4}{5}x+\\frac{3}{5},$ for $0 \\leq x \\leq 1$\n",
    "\n",
    "$f_Y(y)=\\int_{-\\infty}^{+\\infty}f(x,y)dx=\\frac{2}{5}\\int_{0}^{1}(2x+3y)dx=\\frac{6}{5}y+\\frac{2}{5},$ for $0 \\leq y \\leq 1$\n",
    "\n",
    "$f_{X \\mid Y}(x \\mid y) = \\frac{f(x,y)}{f_Y(y)}=\\frac{2x+3y}{3y+1},$ for $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$\n",
    "\n",
    "$f_{Y \\mid X}(y \\mid x) = \\frac{f(x,y)}{f_X(x)}=\\frac{4x+6y}{4x+3},$ for $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$\n",
    "\n",
    "## Answer of Question a:\n",
    "\n",
    "The proportion of college students obtain a score greater than 0.8 on the mathematics test is $P(X \\geq 0.8)=1-P(X \\leq 0.8)$\n",
    "\n",
    "$P(X \\leq 0.8)=F_X(x=0.8)=\\int_0^{0.8}(0.8x+0.6)dx=0.736$\n",
    "\n",
    "$P(X \\geq 0.8)=1-P(X \\leq 0.8)=0.264$\n",
    "\n",
    "## Answer of Question b:\n",
    "\n",
    "If a student's score on the music test is 0.3, the probability that his/her score on the mathematics test will be greater than 0.8 is $P(X \\geq 0.8 \\mid Y=0.3)=1-P(X \\leq 0.8 \\mid Y=0.3)$\n",
    "\n",
    "$P(X \\leq 0.8 \\mid Y=0.3)=F_{X \\mid Y}(0.8 \\mid 0.3)=\\int_0^{0.8}\\frac{2x+0.9}{0.9+1}dx=0.7158$\n",
    "\n",
    "$P(X \\geq 0.8 \\mid Y=0.3)=1-P(X \\leq 0.8 \\mid Y=0.3)=0.28$\n",
    "\n",
    "## Answer of Question c:\n",
    "\n",
    "If a student's score on the mathematics test is 0.3, the probability that his/her score on the music test will be greater than 0.8 is $P(Y \\geq 0.8 \\mid X=0.3)=1-P(Y \\leq 0.8 \\mid X=0.3)$\n",
    "\n",
    "$P(Y \\leq 0.8 \\mid X=0.3)=F_{Y \\mid X}(0.8 \\mid 0.3)=\\int_0^{0.8}\\frac{1.2+6y}{1.2+3}dy=0.6857$\n",
    "\n",
    "$P(Y \\geq 0.8 \\mid X=0.3)=1-P(Y \\leq 0.8 \\mid X=0.3)=0.31$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9afe5deed00addacea2ffd902cfd2a76",
     "grade": false,
     "grade_id": "cell-6c53a68749acb988",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "Write out the joint probability distribution described by the following Bayesian Network:\n",
    "\n",
    "![bayes_net](https://docs.google.com/drawings/d/e/2PACX-1vRjJ382tPK3UrxydjCmwWmMjOi-8T1wQN6hBBJhE7u3-creWY7KR-K224MPTU5IzKXtX4ILxviRUMAw/pub?w=720&h=528)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3315e32937e66207191e55de29900077",
     "grade": true,
     "grade_id": "cell-e702292884b97e63",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "## [YOUR ANSWER HERE]\n",
    "\n",
    "$$P(A,B,C,D,E,F)=P(A)P(B)P(C)P(D\\mid A,B)P(E\\mid B,C)P(F\\mid D,E)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a8297d74638bd383fc868c1cbdbdc0b7",
     "grade": false,
     "grade_id": "cell-e5b71a52fa68bb04",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 4\n",
    "\n",
    "Given the dataset below, use information gain to calculate the first attribute the decision tree should split on. Feel free to use the cell below to explore the dataset and facilitate with the calculations. You should show your work using LaTeX 2 cells down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 150 samples with 4 attributes.\n",
      "The labels consist of 3 classes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data_iris, labels_iris = load_iris(return_X_y=True)\n",
    "\n",
    "print('There are {} samples with {} attributes.'.format(*data_iris.shape))\n",
    "print('The labels consist of {} classes'.format(len(np.unique(labels_iris))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4e80f0e5cf3bf5fb6848c2d982131821",
     "grade": true,
     "grade_id": "cell-9d85836f00c56d8e",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "## [YOUR ANSWER HERE]\n",
    "\n",
    "By running a python script, I figure out the distribution of all samples as below:\n",
    "\n",
    "| Attributes | Species 1 | Species 2 | Species 3 | Total | \n",
    "| - | - | - | - | - | \n",
    "| Attributes1>=5.5 | 5 | 44 | 49 | 98 | \n",
    "| Attributes1<5.5 | 45 | 6 | 1 | 52 | \n",
    "| Attributes2>=3.0 | 48 | 16 | 29 | 93 | \n",
    "| Attributes2<3.0 | 2 | 34 | 21 | 57 | \n",
    "| Attributes3>=2.0 | 0 | 50 | 50 | 100 | \n",
    "| Attributes3<2.0 | 50 | 0 | 0 | 50 | \n",
    "| Attributes4>=1.0 | 0 | 50 | 50 | 100 | \n",
    "| Attributes4<1.0 | 50 | 0 | 0 | 50 | \n",
    "\n",
    "The entropy of the original data is:\n",
    "\n",
    "$H=-\\frac{1}{3}\\log_2\\frac{1}{3}-\\frac{1}{3}\\log_2\\frac{1}{3}-\\frac{1}{3}\\log_2\\frac{1}{3}=1.585$\n",
    "\n",
    "For Attribute 1:\n",
    "\n",
    "$H_1(>)=-\\frac{5}{98}\\log_2\\frac{5}{98}-\\frac{44}{98}\\log_2\\frac{44}{98}-\\frac{49}{98}\\log_2\\frac{49}{98}$\n",
    "\n",
    "$H_1(<)=-\\frac{45}{52}\\log_2\\frac{45}{52}-\\frac{6}{52}\\log_2\\frac{6}{52}-\\frac{1}{52}\\log_2\\frac{1}{52}$\n",
    "\n",
    "$IG_1=H-\\frac{98}{150}H_1(>)-\\frac{52}{150}H_1(<)<IG_3$\n",
    "\n",
    "For Attribute 2:\n",
    "\n",
    "$H_2(>)=-\\frac{48}{93}\\log_2\\frac{48}{93}-\\frac{16}{93}\\log_2\\frac{16}{93}-\\frac{29}{93}\\log_2\\frac{29}{93}$\n",
    "\n",
    "$H_2(<)=-\\frac{2}{57}\\log_2\\frac{2}{57}-\\frac{34}{57}\\log_2\\frac{34}{57}-\\frac{21}{57}\\log_2\\frac{21}{57}$\n",
    "\n",
    "$IG_2=H-\\frac{93}{150}H_2(>)-\\frac{57}{150}H_2(<)<IG_3$\n",
    "\n",
    "For Attribute 3:\n",
    "\n",
    "$H_3(>)=-\\frac{50}{100}\\log_2\\frac{50}{100}-\\frac{50}{100}\\log_2\\frac{50}{100}$\n",
    "\n",
    "$H_3(<)=-\\frac{50}{50}\\log_2\\frac{50}{50}$\n",
    "\n",
    "$IG_3=H-\\frac{100}{150}H_3(>)-\\frac{50}{150}H_3(<)=0.9183$\n",
    "\n",
    "For Attribute 4, it is easy to know that $IG_4=IG_3=0.9183$\n",
    "\n",
    "The attributes which have the most information gain are attribute 3 and 4, so the first attribute the decision tree should split on is either  attribute 3 or attribute 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Given the dataset below, implement the logistic regression algorithm, optimizing the parameters using gradient descent and squared error as the loss function. See 18.6.4 from the textbook for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "75b88d158872f2555802d1ca4e7d57cb",
     "grade": false,
     "grade_id": "cell-3f4f2172ab68f465",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (100,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d94aa11e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets.samples_generator import make_moons\n",
    "\n",
    "np.random.seed(33)\n",
    "data, labels = make_moons(n_samples=100, noise=0.1)\n",
    "colors = ['r' if y else 'b' for y in labels]\n",
    "print(data.shape, labels.shape)\n",
    "plt.scatter(data[:,0], data[:,1], c=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4a753cda013f7b7c1376e8e4d6fd26f9",
     "grade": false,
     "grade_id": "cell-14e8f247a6e4f45c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intial Accuracy:1.0%\n",
      "Step 1 Accuracy:1.0%\n",
      "Step 2 Accuracy:1.0%\n",
      "Step 3 Accuracy:1.0%\n",
      "Step 4 Accuracy:1.0%\n",
      "Step 5 Accuracy:1.0%\n",
      "Step 6 Accuracy:1.0%\n",
      "Step 7 Accuracy:1.0%\n",
      "Step 8 Accuracy:1.0%\n",
      "Step 9 Accuracy:1.0%\n",
      "Step 10 Accuracy:1.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d94be789e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logistic(x, w):\n",
    "    # YOUR CODE HERE\n",
    "    a=[]\n",
    "    for i in range(len(x)):\n",
    "        a.append(np.dot(w,x[i]))\n",
    "    return sigmoid(a)\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def sigmoid(z):\n",
    "    # YOUR CODE HERE\n",
    "    for i in range(len(z)):\n",
    "        z[i] = 1.0/(1.0+np.exp(-z[i]))\n",
    "    return z\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    # YOUR CODE HERE\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def squared_error(y, h):\n",
    "    # YOUR CODE HERE\n",
    "    total=0\n",
    "    for i in range(len(y)):\n",
    "        total += (y[i]-h[i])*(y[i]-h[i])\n",
    "    return total\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def squared_error_derivative(y, h):\n",
    "    # YOUR CODE HERE\n",
    "    sum = 0\n",
    "    for i in range(len(y)):\n",
    "        sum += y[i]-h[i]\n",
    "    return sum\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def accuracy(y, h):\n",
    "    # YOUR CODE HERE\n",
    "    new = 0\n",
    "    old = 0\n",
    "    for i in range(len(y)):\n",
    "        if (y[i] == h[i]).any:\n",
    "            new += 1\n",
    "        else:\n",
    "            old += 1\n",
    "    return new/len(y)\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def logistic_regression(x, y, loss_func, loss_func_derivative, learning_rate, num_steps=10):\n",
    "    # start with intial parameters w_i = 1\n",
    "    w = np.ones(3)\n",
    "    # include a bias term\n",
    "    x = np.pad(x, [[0,0], [1,0]], mode='constant')\n",
    "\n",
    "    print('Intial Accuracy:{}%'.format(accuracy(y, np.round(logistic(x, w)))))\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        output = logistic(x, w)\n",
    "        update = np.dot(loss_func(y, output) * loss_func_derivative(y, output), x)\n",
    "        w = w + learning_rate * update\n",
    "        print('Step {} Accuracy:{}%'.format(step+1,accuracy(y, np.round(logistic(x, w)))))\n",
    "    return w\n",
    "    \n",
    "\n",
    "ws = logistic_regression(data, labels, squared_error, squared_error_derivative, 0.5)\n",
    "yh = np.round(logistic(np.pad(data, [[0,0], [1,0]], mode='constant'), ws))\n",
    "colors = ['g' if (_yh==_y).any else 'r' for _yh, _y in zip(yh, labels.astype(np.int))]\n",
    "plt.title('Classification Results')\n",
    "plt.scatter(data[:,0], data[:,1], c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48af5556e545939d398fc0b508377e08",
     "grade": true,
     "grade_id": "cell-5c2d005f666d2961",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intial Accuracy:1.0%\n",
      "Step 1 Accuracy:1.0%\n",
      "Step 2 Accuracy:1.0%\n",
      "Step 3 Accuracy:1.0%\n",
      "Step 4 Accuracy:1.0%\n",
      "Step 5 Accuracy:1.0%\n",
      "Step 6 Accuracy:1.0%\n",
      "Step 7 Accuracy:1.0%\n",
      "Step 8 Accuracy:1.0%\n",
      "Step 9 Accuracy:1.0%\n",
      "Step 10 Accuracy:1.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-05, atol=0\n\n(shapes (100, 3), (3,) mismatch)\n x: array([[  1.000000e+00,   6.405059e+03,  -1.235354e+04],\n       [  1.000000e+00,   6.013443e+03,  -1.233764e+04],\n       [  1.000000e+00,   5.995818e+03,  -1.239663e+04],...\n y: array([ 1.      ,  0.510032, -1.569645])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f77d4374f8a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m np.testing.assert_allclose(logistic_regression(data, labels, squared_error, squared_error_derivative, 0.5),\n\u001b[0;32m      3\u001b[0m                            \u001b[0mcorrect_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                            rtol=1e-5)\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\testing\\utils.py\u001b[0m in \u001b[0;36massert_allclose\u001b[1;34m(actual, desired, rtol, atol, equal_nan, err_msg, verbose)\u001b[0m\n\u001b[0;32m   1393\u001b[0m     \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Not equal to tolerance rtol=%g, atol=%g'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m     assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n\u001b[1;32m-> 1395\u001b[1;33m                          verbose=verbose, header=header, equal_nan=equal_nan)\n\u001b[0m\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\testing\\utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[1;32m--> 715\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misnumber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misnumber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-05, atol=0\n\n(shapes (100, 3), (3,) mismatch)\n x: array([[  1.000000e+00,   6.405059e+03,  -1.235354e+04],\n       [  1.000000e+00,   6.013443e+03,  -1.233764e+04],\n       [  1.000000e+00,   5.995818e+03,  -1.239663e+04],...\n y: array([ 1.      ,  0.510032, -1.569645])"
     ]
    }
   ],
   "source": [
    "correct_w = np.array([ 1.        ,  0.51003169, -1.56964452])\n",
    "np.testing.assert_allclose(logistic_regression(data, labels, squared_error, squared_error_derivative, 0.5),\n",
    "                           correct_w,\n",
    "                           rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "Implement a single perceptron below.\n",
    "\n",
    "You can assume that both **x** and **w** will be iterables and b will be a single value. All of them will not be *None*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "23ec0179033bbc5ec963ac98baf613fb",
     "grade": false,
     "grade_id": "cell-6ad288911fa0e2a9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def perceptron(x, w, b):\n",
    "    # YOUR CODE HERE\n",
    "    res = b\n",
    "    for i in range(len(x)):\n",
    "        res += x[i]*w[i]\n",
    "    if res >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f8e4fb18f036abcf7180c285e531fd24",
     "grade": true,
     "grade_id": "cell-0beeecf3cc6d7e32",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert perceptron([1, 2], [1, 1], 0) == 1\n",
    "assert perceptron([1, 2], [1, 1], -5) == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
